"""Extractor Agent - ä»ç ”ç©¶åˆ‡ç‰‡ä¸­æŠ½å–ç»“æ„åŒ–æ•°æ®

è¯¥Agentè´Ÿè´£:
1. è¯»å– research_chunk åˆ‡ç‰‡
2. æ ¹æ® expected_fields æŠ½å–ç»“æ„åŒ–æ•°æ®
3. ä¸ºæ¯ä¸ªå­—æ®µç»‘å®šè¯æ®æ¥æº (chunk_uid + quote)
4. è¿”å› {structured, provenance} æ ¼å¼

å…³é”®åŸåˆ™:
- LLMåªæŠ½å–åŸå§‹å€¼ (value_raw)ï¼Œä¸åšå•ä½æ¢ç®—
- æ¯ä¸ªå­—æ®µå¿…é¡»å…³è”åˆ°å…·ä½“çš„chunkä½œä¸ºè¯æ®
- æ”¯æŒé™çº§åˆ°raw_outputçš„ç®€å•è§£æ
"""

import json
import time
from typing import Dict, Any, List, Optional
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from ymda.settings import Settings
from ymda.utils.logger import get_logger

logger = get_logger(__name__)


class ExtractorAgent:
    """ç»“æ„åŒ–æ•°æ®æŠ½å–Agent (chunk-grounded)"""
    
    def __init__(self, settings: Settings):
        """åˆå§‹åŒ–Extractor Agent
        
        Args:
            settings: å…¨å±€é…ç½®
        """
        self.settings = settings
        self.llm = ChatOpenAI(
            model="gpt-4o",
            temperature=0,
            api_key=settings.openai_api_key
        )
        
        # é‡è¯•é…ç½®
        self.max_retries = 3
        self.retry_delay = 2  # seconds
        
        logger.debug("ExtractorAgent åˆå§‹åŒ–æˆåŠŸ")
    
    def _build_extraction_prompt(
        self,
        flattened_fields: Dict[str, Dict[str, Any]],
        chunks: List[Dict[str, Any]]
    ) -> str:
        """æ„å»ºæŠ½å–Promptï¼ˆæ–°ç‰ˆï¼šä½¿ç”¨å¹³é“ºschemaï¼‰
        
        P0-2 ä¿®æ­£ï¼šæ˜ç¡®è‹±æ–‡åŸæ ·è§„åˆ™
        
        Args:
            flattened_fields: å¹³é“ºçš„å­—æ®µæ˜ å°„ {key: field_def}
            chunks: List[{chunk_uid, content}]
            
        Returns:
            æ ¼å¼åŒ–çš„Promptæ–‡æœ¬
        """
        # æ„å»ºå­—æ®µåˆ—è¡¨ï¼ŒåŒ…å«typeä¿¡æ¯ç”¨äºæ ¼å¼æŒ‡å¯¼
        fields_list = []
        for key, field_def in flattened_fields.items():
            field_entry = {
                "key": key,
                "canonical_name": field_def.get("canonical_name"),
                "description": field_def.get("description"),
                "type": field_def.get("type"),  # â­ ä¿ç•™typeç”¨äºæ ¼å¼æŒ‡å¯¼
                "required": field_def.get("required", True)
            }
            # åªåœ¨æœ‰unitæ—¶æ·»åŠ ï¼Œç”¨äºæç¤ºä½†ä¸å¼ºåˆ¶è½¬æ¢
            if field_def.get("unit"):
                field_entry["unit_hint"] = field_def.get("unit")
            fields_list.append(field_entry)
        
        schema_for_llm = {"fields": fields_list}
        fields_json = json.dumps(schema_for_llm, ensure_ascii=False, indent=2)
        
        # æ ¼å¼åŒ–chunks
        chunks_text = ""
        for chunk in chunks:
            chunks_text += f"\n[{chunk['chunk_uid']}]\n{chunk['content']}\n"
        
        prompt = f"""You are a precise data extraction expert.

## Task
Extract structured data from the provided text chunks according to the schema.

## Expected Fields Schema
{fields_json}

## Text Chunks
{chunks_text}

## Critical Requirements

### ğŸ”´ P0-1: Type-Specific Output Formats

**IMPORTANT**: The value format MUST match the field's `type`:

1. **type="range"**: Output as JSON object with min/max
   ```json
   {{"min": 15000, "max": 25000}}
   ```
   - Extract BOTH minimum and maximum values from the text
   - If only one value mentioned, use it for both min and max
   - Values should be numbers (extract from text like "$20k" â†’ 20000)

2. **type="number"**: Output as a single number
   ```json
   12000
   ```

3. **type="text"**: Output as string (preserve original language)
   ```json
   "original text from report"
   ```

4. **type="boolean"**: Output as true/false
   ```json
   true
   ```

5. **type="enum"**: Output as string matching one of the allowed values
   ```json
   "option_value"
   ```

**unit_hint** (if provided): This is a HINT about expected units, but:
- Do NOT convert units
- Extract the numeric value in whatever unit appears in the text
- Example: If text says "Â¥20ä¸‡" and unit_hint is "USD", extract {{"min": 200000, "max": 200000}} (the CNY value)

### ğŸ”´ P0-2: Original Language - No Translation

**IMPORTANT**: Extracted values MUST be in the SAME LANGUAGE as they appear in the report.

Examples:
- âœ… CORRECT: If report says "Operator" (English), extract "Operator"  
- âŒ WRONG: Do NOT translate to Chinese "è¿è¥æ–¹"
- âœ… CORRECT: If report says "$20k", extract numeric value 20000 for range type
- âŒ WRONG: Do NOT keep as string "$20k" for range type
- âœ… CORRECT: For text type, extract the EXACT original expression from the text
- âŒ WRONG: Do NOT convert, translate, or rewrite in ANY language

**Rule**: For text types, copy values EXACTLY as written. For numeric/range types, extract the numeric value.

### Other Requirements

1. **Extract Original Expressions**: Extract values according to their type.
   - For range/number types: Extract numeric values (convert "20k" â†’ 20000)
   - For text types: Keep exact original text
   - Do NOT perform unit conversion between different currencies/units
   - Example: If text says "20k USD", extract 20000 for number type
   - Example: If text says "12 months", extract "12 months" for text type
   
2. **Evidence Binding**: For each field, find the most relevant chunk_uid as evidence
   - quote should be a verbatim excerpt from the chunk that directly supports the field
   - Prefer concise quotes; length is flexible, do NOT pad quotes unnecessarily
   - If multiple chunks mention it, choose the most explicit one
   
3. **Relevance Assessment** (Optional): Set relevance (0.0-1.0) based on evidence clarity
   - 0.9-1.0: Directly and explicitly supports the metric
   - 0.7-0.8: Strongly related but requires inference
   - 0.5-0.6: Moderately related or partially supports
   
4. **Missing Fields**: If a field has no evidence in chunks:
   - Do NOT include the key in "structured"
   - Do NOT output null values
   - Simply omit the field entirely

## Output Format (Strict JSON)
{{
  "structured": {{
    "key1": {{"min": 15000, "max": 25000}},  // for range type
    "key2": 12000,  // for number type
    "key3": "original text"  // for text type
  }},
  "provenance": [
    {{
      "fields": ["key1"],
      "chunk_uid": "rr_123_chunk_0001",
      "quote": "verbatim quote from chunk...",
      "reasoning": "why this quote supports the field",
      "relevance": 0.9
    }}
  ]
}}

## Important Reminders
- Output MUST be valid JSON
- Keys in structured MUST exactly match keys in expected_fields
- â­ **Each key in structured MUST have corresponding entry in provenance** (mandatory)
- provenance cannot be empty (unless structured is also empty)
- **Missing fields**: Do NOT output keys with null values; omit them entirely
- Do NOT add any explanatory text outside JSON
- **P0-2: Values MUST be in original report language - NO translation, NO conversion**

## Example
If structured has 2 fields, provenance must have at least 1 entry covering those fields.
If a field has no evidence, do not include it in structured at all.
"""
        return prompt
    
    def _validate_extraction(
        self,
        extraction: Dict[str, Any],
        expected_fields: Dict[str, Any]
    ) -> bool:
        """éªŒè¯æŠ½å–ç»“æœçš„æ ¼å¼
        
        P0-3 ä¿®æ­£ï¼šæ”¯æŒæ–° provenance æ ¼å¼ {fields[], chunk_uid, quote, reasoning}
        
        Args:
            extraction: LLMè¿”å›çš„æŠ½å–ç»“æœ
            expected_fields: æœŸæœ›çš„å­—æ®µå®šä¹‰
            
        Returns:
            æ˜¯å¦æœ‰æ•ˆ
        """
        # æ£€æŸ¥å¿…é¡»å­—æ®µ
        if "structured" not in extraction or "provenance" not in extraction:
            logger.warning("æŠ½å–ç»“æœç¼ºå°‘å¿…é¡»å­—æ®µ (structured/provenance)")
            return False
        
        # æ£€æŸ¥ç±»å‹
        if not isinstance(extraction["structured"], dict):
            logger.warning("structured ä¸æ˜¯dictç±»å‹")
            return False
        
        if not isinstance(extraction["provenance"], list):
            logger.warning("provenance ä¸æ˜¯listç±»å‹")
            return False
        
        # â­ å…¼å®¹æ€§ä¿®æ”¹ï¼šå…è®¸ structured å’Œ provenance éƒ½ä¸ºç©ºï¼ˆè¡¨ç¤ºæ²¡æœ‰æ‰¾åˆ°æ•°æ®ï¼‰
        # è¿™æ˜¯åˆæ³•çš„æƒ…å†µï¼Œä¸åº”è¯¥è§†ä¸ºæ ¼å¼é”™è¯¯
        if extraction["structured"] and not extraction["provenance"]:
            logger.warning("âš ï¸  provenance ä¸ºç©ºï¼Œä½† structured æœ‰æ•°æ®ï¼Œè¿™ä¸ç¬¦åˆè¦æ±‚")
            logger.warning("   æ¯ä¸ª structured å­—æ®µéƒ½åº”è¯¥æœ‰å¯¹åº”çš„ provenance æ¡ç›®")
            return False
        
        # å¦‚æœéƒ½ä¸ºç©ºï¼Œä¹Ÿæ˜¯åˆæ³•çš„ï¼ˆè¡¨ç¤ºæ²¡æœ‰æ‰¾åˆ°ç›¸å…³æ•°æ®ï¼‰
        if not extraction["structured"] and not extraction["provenance"]:
            logger.info("âœ“ structured å’Œ provenance éƒ½ä¸ºç©ºï¼ˆæœªæ‰¾åˆ°ç›¸å…³æ•°æ®ï¼‰")
            return True # å¦‚æœéƒ½ä¸ºç©ºï¼Œåˆ™è§†ä¸ºæœ‰æ•ˆï¼Œç›´æ¥è¿”å›
        
        # P0-3: æ£€æŸ¥provenanceæ ¼å¼ï¼ˆæ–°æ ¼å¼ï¼‰
        for idx, prov in enumerate(extraction["provenance"]):
            if not isinstance(prov, dict):
                logger.warning(f"provenance[{idx}] ä¸æ˜¯dict")
                return False
            
            # æ–°æ ¼å¼å¿…éœ€å­—æ®µ: fields, chunk_uid, quote
            # å¯é€‰å­—æ®µ: reasoning, relevance
            required_keys = ["fields", "chunk_uid", "quote"]
            for key in required_keys:
                if key not in prov:
                    logger.warning(f"provenance[{idx}] ç¼ºå°‘ {key}")
                    return False
            
            # fields å¿…é¡»æ˜¯æ•°ç»„
            if not isinstance(prov["fields"], list):
                logger.warning(f"provenance[{idx}].fields ä¸æ˜¯list")
                return False
            
            # quote ä¸èƒ½ä¸ºç©º
            if not prov.get("quote", "").strip():
                logger.warning(f"provenance[{idx}].quote ä¸ºç©º")
                return False
        
        logger.debug("æŠ½å–ç»“æœéªŒè¯é€šè¿‡")
        return True
    
    def _simple_fallback_extraction(
        self,
        raw_output: str,
        expected_fields: Dict[str, Any]
    ) -> Dict[str, Any]:
        """é™çº§æ–¹æ¡ˆ: ç®€å•çš„æ­£åˆ™åŒ¹é…æŠ½å–
        
        å½“LLMæŠ½å–å¤±è´¥æ—¶ä½¿ç”¨
        
        Args:
            raw_output: åŸå§‹LLMå“åº”
            expected_fields: æœŸæœ›å­—æ®µ
            
        Returns:
            ç®€åŒ–ç‰ˆæŠ½å–ç»“æœ
        """
        logger.warning("ä½¿ç”¨é™çº§æŠ½å–æ–¹æ¡ˆ (simple fallback)")
        
        # éå¸¸ç®€å•çš„å®ç°ï¼Œå®é™…å¯ä»¥æ›´å¤æ‚
        return {
            "structured": {},
            "provenance": []
        }
    
    def extract(
        self,
        expected_fields: Dict[str, Dict[str, Any]],  # â­ æ”¹ä¸º expected_fields
        chunks: List[Dict[str, Any]],
        raw_output: Optional[str] = None
    ) -> Dict[str, Any]:
        """æ‰§è¡Œç»“æ„åŒ–æ•°æ®æŠ½å–ï¼ˆæ–°ç‰ˆï¼šä½¿ç”¨flattened schemaï¼‰
        
        Args:
            expected_fields: å¹³é“ºçš„å­—æ®µæ˜ å°„ {key: field_def}
            chunks: æ–‡æœ¬åˆ‡ç‰‡ List[{chunk_uid, content}]
            raw_output: åŸå§‹LLMå“åº” (ç”¨äºfallback)
            
        Returns:
            {
              "structured": {key: value_raw},
              "provenance": [{key, chunk_uid, quote, relevance}]
            }
        """
        if not chunks:
            logger.warning("æ²¡æœ‰chunkså¯ç”¨äºæŠ½å–ï¼Œè¿”å›ç©ºç»“æœ")
            return {"structured": {}, "provenance": []}
        
        # æ„å»ºPromptï¼ˆä¼ é€’expected_fieldsï¼‰
        prompt_text = self._build_extraction_prompt(expected_fields, chunks)
        
        # é‡è¯•æœºåˆ¶
        for attempt in range(self.max_retries):
            try:
                logger.info(f"æ‰§è¡ŒæŠ½å– (å°è¯• {attempt + 1}/{self.max_retries})")
                
                # è°ƒç”¨LLM (ä½¿ç”¨JSON mode)
                messages = [
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªç²¾ç¡®çš„æ•°æ®æŠ½å–ä¸“å®¶ã€‚åªè¿”å›JSONæ ¼å¼çš„ç»“æœã€‚"},
                    {"role": "user", "content": prompt_text}
                ]
                
                response = self.llm.invoke(
                    messages,
                    response_format={"type": "json_object"}
                )
                
                # è§£æJSON
                extraction = json.loads(response.content)
                
                # â­ è°ƒè¯•ï¼šå¦‚æœ structured ä¸ºç©ºï¼Œè®°å½•å®Œæ•´å“åº”
                if not extraction.get('structured'):
                    logger.warning(f"âš ï¸ LLM è¿”å›äº†ç©ºçš„ structured æ•°æ®")
                    logger.warning(f"å®Œæ•´å“åº”å†…å®¹: {response.content[:1000]}")
                
                # éªŒè¯æ ¼å¼
                if self._validate_extraction(extraction, expected_fields):
                    logger.info(f"æŠ½å–æˆåŠŸ: {len(extraction['structured'])} ä¸ªå­—æ®µ")
                    
                    # â­ å…¼å®¹æ€§ï¼šå¦‚æœ structured ä¸ºç©ºä½†æ ¼å¼æ­£ç¡®ï¼Œä¹Ÿç®—æˆåŠŸï¼ˆé¿å…æ— é™é‡è¯•ï¼‰
                    if not extraction.get('structured'):
                        logger.warning(f"âš ï¸ æŠ½å–ç»“æœä¸ºç©ºï¼Œå¯èƒ½æ˜¯æŠ¥å‘Šä¸­æ²¡æœ‰ç›¸å…³æ•°æ®")
                        logger.warning(f"æœŸæœ›çš„å­—æ®µ: {list(expected_fields.keys())}")
                    
                    return extraction
                else:
                    logger.warning(f"æŠ½å–ç»“æœéªŒè¯å¤±è´¥ï¼Œé‡è¯•...")
                    if attempt < self.max_retries - 1:
                        time.sleep(self.retry_delay)
                        continue
                
            except json.JSONDecodeError as e:
                logger.error(f"JSONè§£æå¤±è´¥: {e}")
                if attempt < self.max_retries - 1:
                    time.sleep(self.retry_delay)
                    continue
                
            except Exception as e:
                logger.error(f"æŠ½å–å¤±è´¥: {e}")
                if attempt < self.max_retries - 1:
                    time.sleep(self.retry_delay)
                    continue
        
        # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥ï¼Œä½¿ç”¨é™çº§æ–¹æ¡ˆ
        logger.error("æ‰€æœ‰æŠ½å–å°è¯•éƒ½å¤±è´¥ï¼Œä½¿ç”¨é™çº§æ–¹æ¡ˆ")
        if raw_output:
            return self._simple_fallback_extraction(raw_output, expected_fields)
        else:
            return {"structured": {}, "provenance": []}
    
    def extract_with_validation(
        self,
        expected_fields: Dict[str, Any],
        chunks: List[Dict[str, Any]],
        raw_output: Optional[str] = None,
        validate_against_registry: bool = False
    ) -> Dict[str, Any]:
        """å¸¦é¢å¤–éªŒè¯çš„æŠ½å– (å¯é€‰)
        
        Args:
            expected_fields: å­—æ®µå®šä¹‰
            chunks: æ–‡æœ¬åˆ‡ç‰‡
            raw_output: åŸå§‹å“åº”
            validate_against_registry: æ˜¯å¦éªŒè¯keyåœ¨registryä¸­
            
        Returns:
            æŠ½å–ç»“æœ
        """
        extraction = self.extract(expected_fields, chunks, raw_output)
        
        if validate_against_registry:
            # TODO: å¯ä»¥æ·»åŠ registry keyéªŒè¯
            pass
        
        return extraction
